import sys
from pathlib import Path
import traceback
from typing import Dict

import graphviz
import networkx as nx
import yaml

from . import ast, cli, compiler, inference, labshare, plugins, run_local, utils #, utils_graphs
from .schemas import wic_schema
from .wic_types import GraphData, GraphReps, Json, StepId, Yaml, YamlTree


def main() -> None:
    """See docs/userguide.md"""
    args = cli.parser.parse_args()

    tools_cwl = plugins.get_tools_cwl(Path(args.cwl_dirs_file), args.validate_plugins,
                                      not args.no_skip_dollar_schemas)
    # This takes ~1 second but it is not really necessary.
    #utils_graphs.make_plugins_dag(tools_cwl, args.graph_dark_theme)
    yml_paths = plugins.get_yml_paths(Path(args.yml_dirs_file))

    # Perform initialization via mutating global variables (This is not ideal)
    compiler.inference_rules = dict(utils.read_lines_pairs(Path('inference_rules.txt')))
    inference.renaming_conventions = utils.read_lines_pairs(Path('renaming_conventions.txt'))

    # Generate schemas for validation and vscode IntelliSense code completion
    yaml_stems = utils.flatten([list(p) for p in yml_paths.values()])
    schema_store: Dict[str, Json] = {}
    validator = wic_schema.get_validator(tools_cwl, yaml_stems, schema_store, write_to_disk=True)

    # Generating yml schemas every time takes ~20 seconds and guarantees the
    # subworkflow schemas are always up to date. However, since it compiles all
    # yml files, if there are any errors in any of the yml files, the user may
    # be confused by an error message when the --yaml file is correct.
    # For now, require the user to update the schemas manually. In the future,
    # we may use a filewatcher.
    if args.generate_schemas_only:
        yml_paths_tuples = [(yml_path_str, yml_path)
            for yml_namespace, yml_paths_dict in yml_paths.items()
            for yml_path_str, yml_path in yml_paths_dict.items()]

        for yml_path_str, yml_path in yml_paths_tuples:
            schema = wic_schema.compile_workflow_generate_schema(yml_path_str, yml_path,
                                                                 tools_cwl, yml_paths, validator)
            # overwrite placeholders in schema_store. See comment in get_validator()
            schema_store[schema['$id']] = schema

        # Now that we compiled all of the subworkflows once with the permissive/weak schema,
        # compile the root yml workflow again with the restrictive/strict schema.
        validator = wic_schema.get_validator(tools_cwl, yaml_stems, schema_store, write_to_disk=True)

    if args.generate_schemas_only:
        print('Finished generating schemas. Exiting.')
        sys.exit(0)

    yaml_path = args.yaml
    yaml_stem = Path(args.yaml).stem

    # Load the high-level yaml root workflow file.
    with open(yaml_path, mode='r', encoding='utf-8') as y:
        root_yaml_tree: Yaml = yaml.safe_load(y.read())
    Path('autogenerated/').mkdir(parents=True, exist_ok=True)
    wic = {'wic': root_yaml_tree.get('wic', {})}
    plugin_ns = wic['wic'].get('namespace', 'global')
    step_id = StepId(yaml_path, plugin_ns)
    y_t = YamlTree(step_id, root_yaml_tree)
    yaml_tree_raw = ast.read_ast_from_disk(y_t, yml_paths, tools_cwl, validator)
    # Write the combined workflow (with all subworkflows as children) to disk.
    with open(f'autogenerated/{Path(yaml_path).stem}_tree_raw.yml', mode='w', encoding='utf-8') as f:
        f.write(yaml.dump(yaml_tree_raw.yml))
    yaml_tree = ast.merge_yml_trees(yaml_tree_raw, {}, tools_cwl)
    with open(f'autogenerated/{Path(yaml_path).stem}_tree_merged.yml', mode='w', encoding='utf-8') as f:
        f.write(yaml.dump(yaml_tree.yml))

    if args.cwl_inline_subworkflows:
        while True:
            # Inlineing changes the namespaces, so we have to get new namespaces after each inlineing operation.
            namespaces_list = ast.get_inlineable_subworkflows(yaml_tree, tools_cwl, False, [])
            if namespaces_list == []:
                break

            #print('inlineing', namespaces_list[0])
            yaml_tree = ast.inline_subworkflow(yaml_tree, tools_cwl, namespaces_list[0])

        with open(f'autogenerated/{Path(yaml_path).stem}_tree_merged_inlined.yml', mode='w', encoding='utf-8') as f:
            f.write(yaml.dump(yaml_tree.yml))

    rootgraph = graphviz.Digraph(name=yaml_path)
    rootgraph.attr(newrank='True') # See graphviz layout comment above.
    rootgraph.attr(bgcolor="transparent") # Useful for making slides
    font_edge_color = 'black' if args.graph_dark_theme else 'white'
    rootgraph.attr(fontcolor=font_edge_color)

    # This can be used to visually 'inline' all subworkflows (but NOT the CWL).
    # rootgraph.attr(style='invis')
    # Note that since invisible objects still affect the graphviz layout (by design),
    # this can be used to control the layout of the individual nodes, even if
    # you don't necessarily want subworkflows.

    #rootgraph.attr(rankdir='LR') # When --graph_inline_depth 1, this usually looks better.
    with rootgraph.subgraph(name=f'cluster_{yaml_path}') as subgraph_gv:
        # get the label (if any) from the workflow
        step_i_wic_graphviz = yaml_tree.yml.get('wic', {}).get('graphviz', {})
        label = step_i_wic_graphviz.get('label', yaml_path)
        subgraph_gv.attr(label=label)
        subgraph_gv.attr(color='lightblue')  # color of cluster subgraph outline
        subgraph_nx = nx.DiGraph()
        graphdata = GraphData(yaml_path)
        subgraph = GraphReps(subgraph_gv, subgraph_nx, graphdata)
        try:
            compiler_info = compiler.compile_workflow(yaml_tree, args, [], [subgraph], {}, {}, {}, {},
                                                      tools_cwl, True, relative_run_path=True, testing=False)
        except Exception as e:
            # Certain constraints are conditionally dependent on values and are
            # not easily encoded in the schema, so catch them here.
            # Moreover, although we check for the existence of input files in
            # stage_input_files, we cannot encode file existence in json schema
            # to check the python_script script: tag before compile time.
            print('Failed to compile', yaml_path)
            print(f'See error_{yaml_stem}.txt for detailed technical information.')
            # Do not display a nasty stack trace to the user; hide it in a file.
            with open(f'error_{yaml_stem}.txt', mode='w', encoding='utf-8') as f:
                traceback.print_exception(e, file=f)
            sys.exit(1)
        rose_tree = compiler_info.rose

    utils.write_to_disk(rose_tree, Path('autogenerated/'), relative_run_path=True)

    if args.run_compute:
        # Inline compiled CWL if necessary, i.e. inline across scattering boundaries.
        # NOTE: Since we need to distribute scattering operations across all dependencies,
        # and due to inference, this cannot be done before compilation.
        rose_tree = ast.inline_subworkflow_cwl(rose_tree)
        utils.write_to_disk(rose_tree, Path('autogenerated/'), relative_run_path=True)
        labshare.upload_all(rose_tree, tools_cwl, args, True)

    # Render the GraphViz diagram
    rootgraph.render(format='png') # Default pdf. See https://graphviz.org/docs/outputs/
    #cmd = f'cwltool --print-dot autogenerated/{yaml_stem}.cwl | dot -Tsvg > autogenerated/{yaml_stem}.svg'
    #sub.run(cmd, shell=True, check=False)
    #rootgraph.view() # viewing does not work on headless machines (and requires xdg-utils)

    if args.run_local:
        run_local.run_local(args, rose_tree)


if __name__ == '__main__':
    main()
